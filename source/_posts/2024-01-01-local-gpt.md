---
layout: post
title: 70 行代码实现问答型商品推荐系统
status: publish
type: post
category: 不务正业的 R
published: true
---

本文可以帮助大家理解，大模型是如何同平常的生活结合在一起的。

# 1. 本地知识库助手做啥的？

假如你叫刘弱西，现在经营一家售卖食品的电商平台 Bmazon，拥有 70000 件各类食品（包括零食、高点、巧克力、糖果、猫粮、狗粮……），以及这些商品对应的描述和购买评价。你希望有一个机器人客服，它能通过和客户对话，总结顾客购买的潜在意图，并给出推荐商品。这样聪明的机器人能不能做一个呢？

假想其中的一个问题是：

> 有什么好吃的坚果推荐买吗？

先别看答案，闭上眼睛暂停十秒钟！如果你是机器人客服，你会怎么回答？

....

这个机器人这样回答的：

> 这些商品是各类坚果产品，包括混合坚果、坚果棒和单品种坚果如碧根果和夏威夷果等。它们的特点是：品质上乘，口感绝佳，深受大人小孩喜爱；部分产品采用完美配比，融合了杏仁、蜂蜜烤花生、芝麻棒、黑巧克力裹 soy 坚果以及软糯的核桃和山核桃，甜度适中；部分坚果无盐且新鲜美味，特别适合健康饮食需求，如控制血压者食用；有些产品提供大包装，经济实惠；还有自制混合坚果与干果，适合早餐搭配，营养丰富。另外，部分品牌因其出色的产品线和快速免费送货服务而受到高度推荐。总体而言，这些坚果产品不仅美味可口，还具有多种健康益处，是聚会、节日礼物或日常零食的理想选择。

以及相关的商品推荐，您可以在 Bmazon 上购买：

- [Planters Trail Mix, Energy Mix](https://www.amazon.com/gp/product/B00113OZQK)
- [Eat Natural Bars: Almond & Raisin with Brazil Nuts & Peanuts](https://www.amazon.com/gp/product/B000F70SO6)
- [Planters Mixed Nuts, Antioxidant Mix](https://www.amazon.com/gp/product/B003VMY2J4) 

这三款产品，它们长这个样子：

<img src="/upload/pic/nuts.jpg" width="500px"/>

是不是很神奇？这个引擎可以用 70 行代码实现。喔？有点意思……且听我讲讲怎么实现这个引擎。

<!-- more -->

# 2. 原料准备

我们要构建一个问答型的商品推荐系统，领域内的文本是关键。知乎上的问答显然无法支撑这个想法，亚马逊的商品评论数据则是很好的选择。当有了这些文本数据后，领域内的互动就能够做到了。但还需要一个对话模型，在多番对比之后（OpenAI、本地部署、国产大模型……），最终选用了阿里通义千问大语言模型。

1. 本地知识库：Amazon 在 1999 - 2012 年 25 万用户在 7 万食物商品上的 56 万条[评论详情](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews/data)，
2. 可调用的高性能的大模型：[阿里通义千问的 720 亿参数规模的 Qwen-72B ](https://tongyi.aliyun.com)。这里鄙视一下 OpenAI，在国内死活调不通！

## 2.1. Amazon 的购买数据

原始数据是这个样子的（部分）：

| Id|ProductId  |UserId         |ProfileName                       | Score|       Time|
|--:|:----------|:--------------|:---------------------------------|-----:|----------:|
|  1|B001E4KFG0 |A3SGXH7AUHU8GW |delmartian                        |     5| 1303862400|
|  2|B00813GRG4 |A1D87F6ZCVE5NK |dll pa                            |     1| 1346976000|
|  3|B000LQOCH0 |ABXLMWJIXXAIN  |Natalia Corres ""Natalia Corres"" |     4| 1219017600|
|  4|B000UA0QIQ |A395BORC6FGVXV |Karl                              |     2| 1307923200|
|  5|B006K2ZZ7K |A1UQRSCLF8GW1T |Michael D. Bigham ""M. Wassir""   |     5| 1350777600|
|  6|B006K2ZZ7K |ADT0SRK1MGOEU  |Twoapennything                    |     4| 1342051200|

以及我们最关心的评论文本，比如 ID = 1 的用户是这么评价：

>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.

ID = 2 的用户的评价文本是这样：

>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as ""Jumbo"".

用户数据里面会存在大量非英文字符，以及超链接相关的文本。当然用正则表达式处理起来也容易。

## 2.2. 阿里通义千问大模型

Qwen-7B, Qwen-72B, Qwen-Plus 等都做了一下对比，效果最好的还是千亿级别超大规模语言模型 Qwen-Max。刚好本周阿里团队到公司有一次交流，详细询问了一下各类模型使用细节。阿里的产品同事也推荐使用 Qwen-Max，是所有阿里体系中最优的大模型，当然也最贵。它的 API 限定用户输入为 6k tokens，对于这个场景是没有问题的。使用 Python 调用仅需要安装一个包：

> pip3 install dashscope


## 2.3. 技术框架

核心的步骤只有 4 步：

1. 通过 embedding 技术，将所有评论映射到低维向量空间
2. 将查询的 Query 利用同样的 embedding 技术，转化为低维向量
3. 比对 Query 和评论的相似度（向量相似），召回最相似评论的集合（Chunks）
4. 将这些 Chunks 重新组织成 prompt 丢进大模型里，利用大模型的语言组织能力返回答案，同时返回商品清单。

以上第 2 步是问答型商品推荐系统用户的问询部分，也是唯一的输入。第 4 步是返回的部分，包含了回答内容、商品链接、商品图片三部分。

## 2.4. 细节

想象一下用户的问询：

>有什么好吃的坚果推荐买吗？

这里面有这几个关键词：好吃、坚果、推荐、买。如果用户的意图可以通过这四个词的向量 ***相加*** 就好了，甚至用户表达了：我不喜欢混合坚果。那么，混合这个词能够用 ***减去*** 的方式来计算，那就完美了！要满足这样的设想，显然源自于斯坦福大学的 GloVe 算法是最完美的，算法细节客官可以参见[这里](https://nlp.stanford.edu/projects/glove/)，比如这是官网中通过语料训练得到的词汇间的关系。

![man-woman](https://nlp.stanford.edu/projects/glove/images/man_woman.jpg)

可以看到以上这些单词从身份、性别、血缘维度上看，非常微妙地组织在了一起。当然最让人兴奋的是 man - woman, king - queen, brother - sister 这三组距离基本是相等的。

>既然 man - woman = king - queen，那么 queen = king - man + woman！

这个算法原理显然适合于我们对于用户 query 的理解。



# 3. 关键中间过程

70 行详细实现代码我放在了全文之后，这里摘取一部分中间的关键过程，用于说明实现细节。第一部分是单词的向量示例，仅取了前 5 维（总计 50 维）：

|    word     |     d1    |     d2    |   d3      |    d4     |  d5       |
|:------------:|:----------:|:----------:|:----------:|:----------:|:----------:|
|caloriesbut  |  0.5328530| -0.1984420|  0.2264205| -1.0080164|  0.5556314|
|caloriesthey |  0.0441083| -0.0377092|  0.7923388|  0.3361781| -0.2935881|
|cameron      |  0.3276865|  0.6343640|  0.4496154|  0.5232927|  0.4964200|
|campari      | -0.0778625| -0.2173479|  0.7414341|  0.1315289|  0.3475144|
|cancellation |  0.3215747|  0.3530505|  0.1590252| -0.1406696|  0.8450537|
|cannery      | -0.1270566|  0.7451063| -0.2597326|  0.3438343|  0.2620469|

第二部分是评论向量，既然我们使用 GloVe 算法，那么整段评论就是 token 的 ***加和***，可以观察评论的向量示例，仅取了前 5 维（总计 50 维）：

| 文档 ID |  d1    |     d2    |   d3      |    d4     |  d5       |
|:-:|:----------:|:----------:|:----------:|:----------:|:----------:|
|1| -14.447007|  3.1292817| -0.3561071| -0.9769334|  -2.860675|
|2|  -3.222029| -4.7744274| -3.7621354|  0.3966443|   1.386935|
|3|   2.763255| -9.1535688| -7.3250024|  2.7009571| -12.357563|
|4|  -1.442423| -0.1724862| -4.4917097|  5.1961193|  -5.733810|
|5|  -2.280725| -4.8218712| -7.2149368|  2.8688157|  -1.977257|

基于以上两部分，就可以找到用户发起 query 的相似评论。例如，通过 cat, food, healthy 三个词召回的相似评论：

> [1] "this is an amazingly healthy food for all cats as previously reviewed  of the protein is from rabbit chicken salmon and herring meals since cats are carnivores i think it makes sense to go for something that is grainfree and glutenfree  i mix it with evo for variety for my two cats they are active indoor cats with gorgeous coats and of healthy weightfor a cat of a friend of mine this rabbitbased food has been a livesaver her cat had such sensitive skin that even on premium pet store brands the poor animal had hardly any fur left on its belly from overgrooming itself they tried everything since switching to instinct rabbit meal formula the cat is happy healthy and recovered"                                                                      
> 
> [2] "i love this cat food for my cat its the healthiest i could find for my budget innova foods are too expensive but this cat food is not that bad and its very healthy my kitty is very healthy and has the shiniest coat and when i take her to the vet they always find her in perfect health my kitty loves it and is not overweight at all"                                                                                                                                     
> 
> [3] "my cas love this high quality healthy food wellness pouches are a great food for all cats of all ages"  

把这些文本评论，拼接在下段话之后。同时向大模型发问（Prompt 工程）：

> 下面的英文由多款商品的评论构成，请将这些商品的特性做一个中文总结，字数不超过 150 字：

大模型会返回人类能够理解，且非常精炼的答案。

# 4. 已有的现成技术方案

使用大模型构建本地知识库助手时，两种常见的方法是 fine-tuning 和 embedding 技术。前者需要的硬件资源巨大，可不是我本地丐版 MacBook Air 玩不转。Embedding 的技术框架更为简单，并且还有个无法拒绝的诱惑：一旦本地知识库有了新增或更新，embedding 重新训练模型的成本几乎可以忽略不计。

所以在业界中比较广泛应用的就是 embedding 技术，典型的代表就是[Langchain-ChatGLM](https://github.com/chatchat-space/Langchain-Chatchat)，现已更名为 LangChain-Chatchat。这个项目实现原理如下图所示，过程包括

>加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 top k个 -> 匹配出的文本作为上下文和问题一起添加到 prompt中 -> 提交给 LLM生成回答

总共大概 15 个步骤：

![](/upload/pic/langchain.png)

# 5. 工程化讨论

## 5.1. 向量数据库

## 5.2. 如何处理历史偏好

## 5.3. 语料中没有的答案

# 6. 实现代码

```r
## 使用数据 https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews/data
library(data.table)
library(stopwords)
require(text2vec)
library(stringr)
file <- '/Users/liusizhe/Downloads/archive/Reviews.csv'
x <- fread(file)
x <- x[!duplicated(x$Text), ] # 为了简化问题，剔除重复的评价
str_pipe <- function(text) {
  text |> str_replace_all('<a href=.*/a>', '') |> # 剔除商品超链接
    str_replace_all("<[^>]+>", '') |> # 剔除这种 <br /br>
    str_replace_all("[[:punct:]]", '') |> # 剔除符号，如,.等
    str_replace_all("\\d+", '') |> # 剔除数字
    tolower() # 全部小写化
}
z <- str_pipe(x$Text) # 获得干净的文本内容
tokens <- paste(z, sep = ' ') |> space_tokenizer() # 利用空白 tokens 化
it = itoken(tokens, progressbar = FALSE)
## 构建 vocabulary 并剔除停止词，以及剔除词频过低的 term
vocab <- create_vocabulary(it, stopwords = stopwords()) |>
  prune_vocabulary(term_count_min = 15L)
vectorizer <- vocab_vectorizer(vocab)
## 构建 term-co-occurence matrix 和 document-term matrix
tcm <- create_tcm(it, vectorizer, skip_grams_window = 5L)
dtm <- create_dtm(it, vectorizer)

## 通过 GloVe 算法将 tcm 分解为 rank = 50 的向量
glove <- GlobalVectors$new(rank = 50, x_max = 10)
wv_main <- glove$fit_transform(
  tcm,
  n_iter = 10,
  convergence_tol = 0.01,
  n_threads = 8
)

## 获得词向量
wv_context <- glove$components
word_vectors <- wv_main + t(wv_context)
## 构建 document 的 rank 表征向量
document_vectors <- dtm %*% word_vectors

##  用户 query 信息处理成提供给大模型的 prompt
prompt_words <- "下面的英文由多款商品的评论构成，请将这些商品的特性做一个中文总结，字数不超过 150 字："
query2chunks <- function(x, review, db, hint) {
  st_token <- x |>
    str_pipe() |>
    space_tokenizer() |>
    unlist()
  id_new <- match(st_token, vocab$term, nomatch = 0)
  new_vector <- word_vectors[id_new, ] |> colSums() |> t()
  cos_sim = sim2(
    x = as.matrix(db),
    y = new_vector,
    method = "cosine",
    norm = "l2"
  ) # 同 document 对比相似性，返回最相似的前 10 个
  nn <-
    head(sort(cos_sim[, 1], decreasing = TRUE), 10) |> names() |> as.numeric()
  query_info <-
    review[nn] |> unique() |> paste(collapse = ' ')
  prompt <- paste(hint, query_info, sep = '')
  return(list (text = prompt, n = nn))
}
prompt <-
  query2chunks(
    x = "Are there any delicious nuts recommended to buy?",
    review = z,
    db = document_vectors,
    hint = prompt_words
  )

## 调用阿里通义大模型
require(reticulate)
use_python("/usr/local/bin/python3")
dashscope <- import('dashscope') # pip3 install dashscope
dashscope$api_key <- 'sk-8b7fa826160749308257f5bf21bb2896'
response <- dashscope$Generation$call(model = 'qwen-max',
                                      messages = list(dict(
                                        role = 'user', content = prompt$text
                                      )))
## 打印阿里通义大模型的结果，并返回推荐商品 id
response$output$text
paste('https://www.amazon.com/gp/product/', x$ProductId[prompt$n], sep = '')
```